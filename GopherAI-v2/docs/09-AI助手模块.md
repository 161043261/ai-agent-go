# AI 助手模块 (common/aihelper/)

## 1. 模块概述

AI 助手模块是项目的核心，负责管理 AI 模型实例、会话上下文、消息处理。采用工厂模式支持多种 AI 模型。

## 2. 文件结构

```
common/aihelper/
├── aihelper.go   # AIHelper 核心实现
├── factory.go    # AI 模型工厂
├── manager.go    # AIHelper 管理器
└── model.go      # AI 模型实现（OpenAI/Ollama/RAG/MCP）
```

## 3. 核心结构体

### 3.1 AIHelper

```go
type AIHelper struct {
    model     AIModel           // AI 模型实例
    messages  []*model.Message  // 消息历史
    mu        sync.RWMutex      // 读写锁
    SessionID string            // 会话 ID
    saveFunc  func(*model.Message) (*model.Message, error) // 消息保存回调
}
```

### 3.2 AIModel 接口

```go
type AIModel interface {
    GenerateResponse(ctx context.Context, messages []*schema.Message) (*schema.Message, error)
    StreamResponse(ctx context.Context, messages []*schema.Message, cb StreamCallback) (string, error)
    GetModelType() string
}

type StreamCallback func(chunk string) error
```

### 3.3 AIHelperManager

```go
type AIHelperManager struct {
    helpers map[string]map[string]*AIHelper // map[用户名]map[会话ID]*AIHelper
    mu      sync.RWMutex
}
```

## 4. 支持的 AI 模型

| 类型 | 模型名 | 说明 |
|------|--------|------|
| "1" | OpenAIModel | OpenAI/兼容 API（如通义千问） |
| "2" | AliRAGModel | RAG 增强检索模型 |
| "3" | MCPModel | MCP 协议工具调用 |
| "4" | OllamaModel | 本地 Ollama 模型 |

## 5. 主要函数

### 5.1 AIHelper 方法

```go
// 创建 AIHelper
func NewAIHelper(model AIModel, sessionID string) *AIHelper

// 设置消息保存回调
func (h *AIHelper) SetSaveFunc(f func(*model.Message) (*model.Message, error))

// 添加消息
func (h *AIHelper) AddMessage(content, userName string, isUser bool, save bool) *model.Message

// 同步生成回复
func (h *AIHelper) GenerateResponse(userName string, ctx context.Context, question string) (string, error)

// 流式生成回复
func (h *AIHelper) StreamResponse(userName string, ctx context.Context, cb StreamCallback, question string) (string, error)

// 获取消息历史
func (h *AIHelper) GetMessages() []*model.Message
```

### 5.2 Manager 方法

```go
// 获取全局管理器单例
func GetGlobalManager() *AIHelperManager

// 获取或创建 AIHelper
func (m *AIHelperManager) GetOrCreateAIHelper(
    userName, sessionID, modelType string,
    cfg *config.Config,
    saveFunc func(*model.Message) (*model.Message, error),
) (*AIHelper, error)

// 添加已有消息（启动时加载）
func (m *AIHelperManager) AddExistingMessage(userName, sessionID string, msg *model.Message)
```

### 5.3 Factory 方法

```go
// 获取全局工厂单例
func GetGlobalFactory() *AIModelFactory

// 创建 AI 模型
func (f *AIModelFactory) CreateModel(modelType string, cfg *config.Config, userName string) (AIModel, error)
```

## 6. 工作流程

### 6.1 消息发送流程

```
用户发送消息
    │
    ▼
GetOrCreateAIHelper()
    │
    ├── 检查内存中是否存在
    │   ├── 存在 → 返回已有实例
    │   └── 不存在 → 创建新实例
    │
    ▼
AIHelper.AddMessage(question, userName, true, true)
    │   └── isUser=true, save=true → 消息入队
    │
    ▼
AIHelper.GenerateResponse() / StreamResponse()
    │
    ├── 转换消息格式 → schema.Message
    │
    ├── 调用 model.GenerateResponse() / StreamResponse()
    │
    └── AIHelper.AddMessage(answer, "", false, true)
        └── isUser=false → AI 消息入队
    │
    ▼
返回 AI 回复
```

### 6.2 Manager 数据结构

```
AIHelperManager.helpers
    │
    ├── "user001"
    │   ├── "session-uuid-1" → AIHelper { model, messages, ... }
    │   └── "session-uuid-2" → AIHelper { model, messages, ... }
    │
    └── "user002"
        └── "session-uuid-3" → AIHelper { model, messages, ... }
```

## 7. 模型实现

### 7.1 OpenAIModel

```go
type OpenAIModel struct {
    chatModel *openai.ChatModel
}

// 配置
- BaseURL: https://dashscope.aliyuncs.com/compatible-mode/v1
- Model: qwen-turbo
- APIKey: 环境变量 DASHSCOPE_API_KEY
```

### 7.2 AliRAGModel

```go
type AliRAGModel struct {
    chatModel  *openai.ChatModel
    ragQuery   *rag.RAGQuery
    userName   string
}

// 工作流程
1. 用户问题 → RAG 检索相关文档
2. 构建提示词（问题 + 文档上下文）
3. 调用 LLM 生成回复
```

### 7.3 MCPModel

```go
type MCPModel struct {
    chatModel *openai.ChatModel
    mcpClient *mcp.MCPClient
}

// 工作流程
1. LLM 分析用户意图
2. 需要工具 → 调用 MCP 工具
3. 工具结果 → 继续对话生成回复
```

### 7.4 OllamaModel

```go
type OllamaModel struct {
    chatModel *ollama.ChatModel
}

// 配置
- BaseURL: http://localhost:11434
- Model: qwen2.5:0.5b
```

## 8. 依赖关系

```
common/aihelper/
    ├── → config              (配置)
    ├── → model               (Message 模型)
    ├── → common/rag          (RAG 检索)
    ├── → common/mcp          (MCP 客户端)
    ├── → cloudwego/eino      (AI 框架)
    └── → eino-ext/*          (模型实现)
```

## 9. 注意事项

1. **并发安全**: Manager 和 Helper 都使用读写锁
2. **内存管理**: 消息存储在内存中，重启后从数据库恢复
3. **模型切换**: 同一会话可以切换模型类型
4. **环境变量**: OpenAI 模型需要 `DASHSCOPE_API_KEY`
